%-------------TO BE COMPLETED-----------------
The planning problem has been studied extensively in various fields like robotics, artificial intelligence, and control theory. In robotics, a classical example of the path planning problem is the \textit{piano-mover's problem}, where the aim is to move a piano from one position to another without colliding with any obstacle. Currently, this problem covers other complications such as non-holonomy, uncertainties, and dynamics.

This chapter introduces the basics of path planning and its application on a single agent. The preliminaries are covered in Section.~\ref{sec:prelims}, with topics like \textit{configuration space} and \textit{graph search algorithms}. Then the basic path planning methods are introduced in Section.~\ref{sec:basic_motion_planning}. Finally, the topic of \textit{kinodynamic} planning is introduced in Section~\ref{sec:kinodynamic}.
\section{Preliminaries}
\label{sec:prelims}
\subsection{Configuration Space}
\label{sec:config_space}
Each distinct situation of a world is called a \textit{state}, $x$, and the set of all possible states is called a \textit{state space}, $X$. The state, $x$, can be transformed to $x'$, by applying an \textit{action}, $u$, as specified by a \textit{state transition function}, $f$, such that:
\begin{align}
	x' = f(x,u)
\end{align}
The set of all possible actions for each state is defined as the \textit{action space}, $U(x)$.

In path planning, we work with a special state space called the \textit{configuration space}, or C-space. The configuration space, $\mathcal{C}$, of a robot is the set of all possible configurations, $x$, that could be achieved by it. The real beauty of C-space is in the way it deals with the obstacles. Suppose that the world, $\mathcal{W}$, contains an obstacle region, $\mathcal{O}$. Assuming that the robot, $\mathcal{A}\subset\mathcal{W}$, the \textit{obstacle region}, $\mathcal{C}_{obs}\subseteq\mathcal{C}$, is defined as
\begin{align}
	\mathcal{C}_{obs} = \{x\in\mathcal{C} | \mathcal{A}(x)\cap\mathcal{O}\neq\emptyset\}
\end{align}
In other words, $\mathcal{C}_{obs}$ is the set of all configurations at which the robot intersects the obstacle region (See Figure.~\ref{fig:conf}). The \textit{free space}, defined as, $\mathcal{C}_{free} = \mathcal{C} \backslash  \mathcal{C}_{obs}$, is the set of all collision free configurations of the robot. 

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{./images/conf_space_1}
		\caption{The generation of the configuration obstacle $\mathcal{C}_{obs}$}
        \label{fig:conf_1}
    \end{subfigure}
     %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
    ~\begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{./images/conf_space_2}
		\caption{The configuration space is obtained by sliding the triangle around the obstacle while keeping them both in contact}
		\label{fig:conf_2}    
	\end{subfigure}
    \caption[Visualization of configuration space obstacle]{Visualization of configuration space obstacle \cite{lavalle2006planning}}
    \label{fig:conf}
\end{figure}


Let $x_I \in \mathcal{C}_{free}$ and $x_G \in \mathcal{C}_{free}$ be the \textit{initial configuration} and  the \textit{final configuration} respectively. A path planning algorithm aims to compute a continuous path starting at $x_I$ and ending at $x_G$. 

\subsection{Graph Search Algorithms}
\label{sec:graph_search_algo}
\textit{State transition graph} is a convenient tool that could be used to approach path planning problems. In the graph $\mathcal{G}$, the states and actions form the vertices $\mathcal{V}$ and directed edges $\mathcal{E}$ respectively. A directed edge  from $x\in X$ to $x'\in X$ exists only if there exists an action $u\in U$ such that $x'=f(x,u)$. With this representation, the graph search algorithms could be directly applied to the path planning problem.

In this section, we cover the major graph search algorithms like breadth first search, length first search and A* search. These forward search algorithms start at the initial state and explores the graph until encountering the goal state. The general template of such algorithms \cite{lavalle2006planning} is shown in Algorithm~\ref{alg:fsearch}.

\begin{algorithm}
\caption{Forward Search}\label{alg:fsearch}
\begin{algorithmic}[1]
%\Procedure{Euclid}{$a,b$}
\State $Q$.Insert($x_I$) and mark $x_I$ as visited
\While{$Q$ not empty}
\State $x\gets Q$.GetFirst()
\If{$x\in X_G$}
\State \textbf{return} SUCCESS
\EndIf
\ForAll{$u\in U(x)$}
\State $x'\gets f(x,u)$
\If{$x'$ not visited}
\State Mark $x'$ as visited
\State $Q$.Insert($x'$)
\Else
\State Resolve duplicate $x'$
\EndIf
\EndFor
\EndWhile
\State \textbf{return} FAILURE
\end{algorithmic}
\end{algorithm}

During the search, there will be three kinds of states. The \textit{unvisited} list consists of all the unexplored states of graph. If a state, along with all its next possible states, have been visited, it is added to the \textit{dead} list. The remaining states, i.e. the explored states with unexplored neighbours, forms the \textit{alive} list. As shown in the Algorithm~\ref{alg:fsearch}, the alive list is stored in a data structure $Q$. The main difference between the search algorithms is in the way they sort $Q$. 

In \textit{breadth first search}, $Q$ is implemented as a First-In-First-Out (FIFO) queue. This results in a uniform expansion of the search frontier. If we make $Q$ a stack, the graph would be explored aggressively in an arbitrary direction, resulting in the \textit{depth first search}. 

If we know the cost of the actions, we could use that to increase the efficiency of the search algorithm. In \textit{Dijkstra's algorithm}, $Q$ is sorted according to the \textit{cost-to-come} function, $C(x)$, which is defined as the minimum cost  of travelling from $x_I$ to $x$ according to the current knowledge. 

In many cases, it is possible to obtain a heuristic estimate of the cost to reach the goal from any state. Let this function be called $\hat{G}(x)$. This knowledge can be exploited to reduce the number of states explored to reach the goal. The \textit{A* search algorithm} sorts $Q$ according to the sum $C(x) + \hat{G}{x}$.


\section{Basic Path Planning Methods}
\label{sec:basic_motion_planning}
As mentioned before, the path planning problems are defined in the configuration space, whereas the graph search algorithms are based on graphs. To connect these problems, we should reformulate the path planning problem, framed on a continuous configuration space, in terms of a graph. This section is dedicated to three different methods of approaching this problem: grid based, potential field based, and sampling based.
\subsection{Grid Based Approach}
\label{sec:grid_search}
In this approach, initially, a grid of locations is sampled in the configuration space. Each vertex $\mathcal{V}$ of the graph represent a configuration. A collision-check function is ran on each grid to check if it is in $\mathcal{C}_{free}$. It is assumed that the grids are close enough in space such that there can be no obstacle between two adjacent grids. In other words, we assume that if two adjacent vertices are in $\mathcal{C}_{free}$, every point in the line joining them is also in the $\mathcal{C}_{free}$. Therefore, we join the vertices by an edge. This discretizes the set of actions, and hence the grid search algorithms can be applied to find the path from the start to the goal. 

Grid based search works well for low dimensional problems. However, this method is computationally infeasible for high-dimensional systems, since the number of points on the grid increase exponentially with configuration space dimension. 

\subsection{Sampling-based Approach}
\label{sec:sampling_search}
Sampling-based search algorithms are the leading methods to tackle higher-dimensional path planning problems. These approaches chooses the points in the configuration space randomly, instead of uniformly, to generate the graph. In other words, the connectivity of $\mathcal{C}_{free}$ is explored by sampling random configurations and trying to connect in a network. Two major sampling-based methods: \textit{probabilistic roadmaps} (PRM) \cite{kavraki1994probabilistic} and \textit{rapidly-exploring random trees} (RRT) \cite{lavalle2006planning}, are discussed in this section.

\subsubsection{Probabilistic Road-Map (PRM)}
Probabilistic roadmap is the preferred method if the initial and goal states are not fixed. This method consists of two stages: preprocessing and query. The pseudocode of this method is shown in Algorithm.~\ref{alg:prm}.
In the preprocessing stage, a random configuration is generated, and neighbours within a predefined distance are connected if all the points in the line joining them are in $\mathcal{C}_{free}$. This step is repeated until a dense graph is generated (see Figure.~\ref{fig:prm}). 

In the query stage, the start and goal configurations are connected to the graph, and an appropriate search algorithm is used to find the path. Once the roadmap has been constructed, it can be used to generate paths between various start and goal locations as long as the environment is static. This justifies the initial cost of constructing the graph. 

However, in many cases, we are only interested in planning between one specific start and goal locations, and therefore, building a roadmap for such problems is wasteful. In such situations, it would be better to consider approaches that explicitly uses the initial and goal locations in approaching the problem.


\begin{algorithm}
\caption{Probabilistic Road-Map}\label{alg:prm}
\begin{algorithmic}[1]
\State $\mathcal{G}$.init($i\gets 0;$)
\While{$i<N$ }
\If {$\alpha(i)\in \mathcal{C}_{free}$}
\State $\mathcal{G}$.add\_vertex($\alpha(i)$); $i\gets i+1$
\For \textbf{each} $q\in \text{NEIGHBORHOOD}(\alpha(i),\mathcal{G})$
\If {(\textbf{not} $\mathcal{G}$.same\_component($\alpha(i),q$)) \textbf{and} CONNECT($\alpha(i),q$)}
\State $\mathcal{G}$.add\_edge($\alpha(i),q$)
\EndIf
\EndFor
\EndIf
\EndWhile
\State \textbf{return} $\mathcal{G}$
\end{algorithmic}
\end{algorithm}

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{./images/prm}
\caption[Preprocessing stage of PRM]{Preprocessing stage of PRM. The new randomly sampled point $\alpha(i)$ is connected to the neighbouring vertices in the roadmap}
\label{fig:prm}
\end{figure}


\subsubsection{Rapidly-Exploring Random Trees (RRT)}
The RRT algorithm explores the space by randomly sampling a space-filling \textit{tree}. A tree is a special graph, with every vertex connected to a single parent. As shown in Algorithm~\ref{alg:rrt}, with each new sample $\alpha(i)$, a vertex $q_s$ is added between it and the nearest state $q_n$ in tree. $q_s$ lies at a distance $\delta$ from $q_n$ on the line joining $\alpha(i)$ and $q_n$. If $\alpha(i)$ lies in the obstacle region, $q_s$ is generated at the edge of the obstacle as shown in Figure~\ref{fig:rrt}. 

This algorithm is very efficient in exploring the free space starting from a configuration. In order to use this for our problem, we usually generate two RRTs, one rooted at the initial configuration and the other at the goal configuration. We then grow both trees until they meet. There are many variations of RRT methods, and they are very effective at tackling high dimensional problems. They can also handle problems with kinodynamic constraints.

\begin{algorithm}
\caption{Rapidly-exploring Random Trees}\label{alg:rrt}
\begin{algorithmic}[1]
\State $\mathcal{G}$.init($q_0$)
\For{$i$ = 1 \textbf{to} $k$}
\State $q_{rand}\gets$RAND\_CONFIG()
\State $q_{near}\gets$NEAREST\_VERTEX($q_{rand},\mathcal{G}$)
\State $q_{new}\gets$NEW\_CONF($q_{near}, q_{rand}, \Delta q$)
\State $\mathcal{G}$.add\_vertex($q_{new}$)
\State $\mathcal{G}$.add\_edge($q_{near},q_{new}$)
\EndFor
\State \textbf{return} $\mathcal{G}$
\end{algorithmic}
\end{algorithm}

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{./images/rrt}
\caption[Tree expansion in RRT]{If the sampled point $\alpha(i)$ lies inside the obstacle region, the new vertex $q_s$ is formed at the boundary of $\mathcal{C}_{obs}$}
\label{fig:rrt}
\end{figure}

The main issue with sampling based approaches is that they are not \textit{complete}: i.e. they cannot guarantee the absence of a path even if they are unable to find it. These algorithms are \textit{probabilistically complete}, which means that with enough points, the probability that it finds an existing solution converges to one.
\subsection{Potential field based Search}
\label{sec:pot_search}
Potential field based approaches generate good results with minimal computations. In this method, the robot (represented in C-space), is treated as a particle under the influence of an artificial potential field. The potential field is designed in such a way that the goal has an \textit{attractive potential} and the obstacles has a \textit{repulsive potential}. This ensures that the robot moves towards the goal while avoiding obstacles. 

As shown in Figure.~\ref{fig:potential}, this method can be visualized as a particle moving on a 2D plane under gravity. The goal and the obstacles are represented by a basin and hills respectively. At every instance, the robot tries to move in a direction along decreasing potential, thereby finally reaching the goal. This is done by using the gradient of the potential function to steer the robot. The control velocity \textbf{v} is chosen as:
\begin{align}
\textbf{v} \propto -\nabla f_c
\end{align}

Using this approach, the robot can generate a path by just knowing the potential function. The potential field can be computed by the knowledge of the robot's position, and local sensor data. Moreover, the gradient could be evaluated by using simple finite difference methods. The simplicity of this method makes it appealing to robotic applications. However, this method may find a non-optimal path, or no path at all if the particle is stuck in a local minima.

%\begin{figure}
%\centering
%\includegraphics[width=0.6\textwidth]{./images/potential_search}
%\caption[Local minima in potential field based search]{Local minima in potential field based search. \cite{siciliano2010robotics}}
%\label{fig:potential_search}
%\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{./images/potential_goal}
		\caption{The goal modelled as an attractive potential field, $f_a$}
        \label{fig:potential_goal}
    \end{subfigure}
     %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
    ~\begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{./images/potential_obs}
		\caption{The obstacles are modelled as a repulsive potential field, $f_r$}
		\label{fig:potential_obs}    
	\end{subfigure}
    ~\begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{./images/potential_combined}
		\caption{The combined potential field, $f_c=f_a+f_r$}
		\label{fig:potential_combined}    
	\end{subfigure}	
    \caption[Visualization of potential field based search]{Visualization of potential field based search \cite{lavalle2006planning}}
    \label{fig:potential}
\end{figure}

\section{Kinodynamic Path Planning}
\label{sec:kinodynamic}
Until now, we assumed that the path between any two configurations can be easily determined. However, this might not always be possible in most planning problems in mechanical systems due to the kinematics and dynamics constraints. Planning in such a situation is called \textit{kinodynamic} path planning. 

A classical approach to this problem is to decompose it into two sub-problems. Initially, collision-free a geometric path, called the quasi-static solution, is computed. It can be visualized as a trajectory that the robot can follow in very slow speeds and reach the goal. In the next step, a constrained optimization problem is solved to minimize the time taken to follow the trajectory while respecting the dynamic constraints. 

This decoupled approach is very efficient in finding feasible paths. However, they do not provide good quality paths since the dynamics is not considered during the path planning stage. To obtain better results, more complex \textit{direct planning} methods are preferred. 

Even though there exists many deterministic approaches like methods based on optimal control, numerical optimization, and grid search, sampling-based approaches are preferred to solving these problems due to their high dimensionality. In this case, we have to rethink the way in which we connect two configurations. 

The direct way to do is to solve a two-point boundary value problem (BVP). However, this is computationally demanding and hence infeasible for most scenarios. If the dynamics is linear or could be linearized about an operation point, we could use LQR based techniques to obtain faster results. Some researchers bypass the solving of BVP by using precomputed \textit{motion primitives}.

The most studied method is the forward propagation of dynamics. New states are generated by performing a feasible action on states that are already generated, typically by using ODE solvers. This method works well with RRT and has generated good results. 

Now that we have seen the complexities of planning in mechanical systems, we move ahead to studying the path planning problem for quadrotors.













